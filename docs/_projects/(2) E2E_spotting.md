---
title: E2E-Spot - Temporal Event Detection in Sports Videos
image: /assets/img/projects/e2e_spot.jpg
description: End-to-end architecture for precise temporal event detection in futsal videos using RegNet-Y, Gate Shift Modules, and Bidirectional GRU for ultra-precise action spotting.
category: sports-analytics
tags:
  - Computer Vision
  - Action Spotting
  - RegNet-Y
  - Deep Learning
  - Temporal Detection
  - Sports Analytics
demo: /assets/videos/e2e_spot_demo.mp4
date: 2025-01-15
company: Research Project
location: Ibn Tofail University, Kenitra
duration: January 2025 - March 2025
---

## ğŸ¯ Project Overview

**E2E-Spot** is an end-to-end architecture for **precise temporal event detection** in sports videos. The system automatically detects key actions (passes, dribbles, shots) at frame-level in futsal matches.

**Team:** Hicham EL MEHDI & Mohammed Imrane GRICH  
**Supervised by:** Prof. Noureddine MOHTARAM

**Key Achievement:** **93% recall** for dribble detection with a lightweight architecture (10M parameters).

---

## ğŸ” Problem Statement

### Challenges
- â±ï¸ **Ultra-precise temporal detection** at frame level (Â±1 second)
- ğŸ¯ **Contextual understanding** to differentiate similar actions
- ğŸ”„ **Temporal relationships** across long sequences
- ğŸ’° **Computational efficiency** for fast video processing

### Solution
End-to-end architecture combining:
- **RegNet-Y:** Efficient visual feature extraction
- **Gate Shift Modules (GSM):** Local temporal modeling
- **Bidirectional GRU:** Global temporal reasoning
- **Frame-by-frame classification** with background detection

---

## ğŸ—ï¸ Technical Architecture

<div align="center">

![E2E-Spot Pipeline Architecture](/assets/img/projects/e2e_spot_architecture.jpg)

**Figure 1: Complete E2E-Spot Pipeline**

</div>

---

### ğŸ”§ Key Components

<table>
<tr>
<td width="50%" valign="top">

#### **Module F: Feature Extraction**

![Gate Shift Modules](/assets/img/projects/e2e_spot_gsm.png)

**RegNet-Y + Gate Shift Modules**
- âš¡ Lightweight: **10M parameters** (vs 25M ResNet-50)
- ğŸ”„ GSM capture variations between adjacent frames
- ğŸš€ Ultra-efficient single-pass processing

</td>
<td width="50%" valign="top">

#### **Module G: Temporal Reasoning**

![GRU Bidirectional](/assets/img/projects/e2e_spot_gru.png)

**Bidirectional GRU**
- ğŸ“Š Models **past + future** context
- ğŸ¯ Global temporal understanding
- ğŸ“ˆ Frame-wise classification with confidence scores

</td>
</tr>
</table>

---

### ğŸ“ Architecture Flow

```mermaid
graph LR
    A[ğŸ¥ Video Frames] --> B[RegNet-Y CNN]
    B --> C[Gate Shift Modules]
    C --> D[Feature Maps]
    D --> E[Bidirectional GRU]
    E --> F[Frame Predictions]
    F --> G[ğŸ“Š Events Timeline]
    
    style A fill:#e1f5ff
    style G fill:#d4edda
    style E fill:#fff3cd
```

<div align="center">

**Input:** RGB frame sequence (Xt-50 ... Xt ... Xt+50)  
â†“  
**Processing:** RegNet-Y + GSM â†’ Features â†’ Bidirectional GRU  
â†“  
**Output:** [PASS | DRIVE | SHOT | Background] per frame

</div>

---

## ğŸ“¦ Dataset & Preprocessing

**Source:** FIFA Futsal World Cup 2024  
**Volume:** 40 GB video data  
**Content:** 7 complete matches (14 halves)

### Preprocessing Pipeline
1. Frame extraction at 30 FPS
2. Temporal normalization (timestamps â†’ seconds)
3. Augmentation: Jittering, cropping, mixup
4. Split: 70% train / 15% val / 15% test

---

## ğŸš€ Training Configurations

### Configuration 1: RegNet-Y (clip_len=50)
```yaml
Model: rny008_gsm
Clip Length: 50 frames (long sequences)
Training Time: 8h 20min
```

### Configuration 2: ResNet-50 (clip_len=16)
```yaml
Model: rn50
Clip Length: 16 frames
Training Time: 300h (~12.5 days)
```

### Configuration 3: RegNet-Y (clip_len=16) â­
```yaml
Model: rny008_gsm
Clip Length: 16 frames (best tradeoff)
Training Time: 450h (~18.7 days)
```

**Hardware:** NVIDIA RTX 4060 (8GB) | AMD Ryzen 7 5700X | 32GB RAM

---

## ğŸ“Š Results & Performance

### Best Configuration: RegNet-Y (clip_len=16)

| Class | Precision | Recall | F1-Score |
|--------|-----------|--------|----------|
| **PASS** | 0.76 | 0.04 | 0.08 |
| **DRIVE** | 0.22 | **0.93** | **0.36** |
| **Overall** | 0.49 | 0.49 | 0.22 |

### Key Insights
- ğŸ† **93% Recall for DRIVE:** Detects almost all dribbles
- ğŸ¯ **Good PASS precision (0.76)** but low recall (class imbalance)
- âš¡ **Lightweight architecture:** 2.5x fewer parameters than ResNet-50
- ğŸ“ˆ **Best tradeoff** performance/efficiency

### Benchmark Comparison

| Model | Recall DRIVE | F1-Score | Parameters |
|--------|--------------|----------|------------|
| **E2E-Spot (RegNet-Y)** | **0.93** | **0.36** | 10M |
| ResNet-50 | 0.55 | 0.32 | 25M |
| RegNet-Y (clip=50) | 0.15 | 0.15 | 10M |

---

## ğŸ› ï¸ Challenges & Solutions

### Challenge 1: Class Imbalance
**Problem:** PASS class underrepresented â†’ low recall  
**Solution:** Weighted Cross-Entropy Loss, PASS oversampling

### Challenge 2: Training Time
**Problem:** 450h for optimal config  
**Solution:** Checkpointing, Mixed Precision (FP16), Gradient Accumulation

### Challenge 3: Temporal Capture
**Problem:** clip_len=50 too long, clip_len=16 sometimes insufficient  
**Future Solution:** Multi-scale temporal fusion (8/16/32 frames)

---

## ğŸ”® Future Improvements

**Short-Term:**
- Focal Loss for class imbalance
- Multi-scale temporal fusion
- Temporal NMS post-processing

**Long-Term:**
- Transformer architecture for very long-term relationships
- Real-time inference (<100ms latency)
- Multi-sport generalization (basketball, handball)

---

## ğŸ’¼ Impact & Value

### For Sports Analytics
âœ… **70% reduction** in manual annotation time  
âœ… **Frame-precise detection** (Â±1 second)  
âœ… **Lightweight architecture** = reduced infrastructure costs  

### For Coaches & Media
âœ… **Fast post-match analysis**  
âœ… **Automatic highlight generation**  
âœ… **Video indexing** for event search  

---

## ğŸ› ï¸ Technical Stack

**Deep Learning:** PyTorch, TorchVision, Lightning  
**Computer Vision:** OpenCV, Albumentations  
**Models:** RegNet-Y, Gate Shift Modules, GRU  
**Tools:** Weights & Biases, TensorBoard  
**Hardware:** NVIDIA RTX 4060, AMD Ryzen 7 5700X

---

## ğŸ“ Skills Developed

- **Deep Learning:** End-to-end architecture, temporal modeling
- **Computer Vision:** Video understanding, action spotting
- **Model Optimization:** Hyperparameter tuning, loss functions
- **Research:** Experimentation, benchmarking, technical writing

---

## ğŸ“§ Contact

**Author:** Hicham El Mehdi  
**Email:** mehdihicham736@gmail.com  
**LinkedIn:** [linkedin.com/in/elmehdihicham](https://linkedin.com/in/elmehdihicham)  
**GitHub:** [github.com/MehdiHCH](https://github.com/MehdiHCH)  

**Co-Author:** Mohammed Imrane GRICH  
**Supervisor:** Prof. Noureddine MOHTARAM

---

## ğŸ“š Key References

1. **RegNet** (Radosavovic et al., 2020) - Designing Network Design Spaces
2. **Gate Shift Modules** (Sudhakaran et al., 2020) - CVPR 2020
3. **E2E-Spot** (Giancola et al., 2022) - End-to-End Spotting in Soccer

---

*Compact and efficient end-to-end architecture for temporal event detection in sports videos, achieving 93% recall with only 10M parameters.*