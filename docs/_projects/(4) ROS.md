---
title: RoboRangers - Voiture Autonome avec Deep Reinforcement Learning
image: /assets/img/projects/roborangers.gif
description: SystÃ¨me de navigation autonome utilisant ROS2, Gazebo et Deep Reinforcement Learning (TD3) pour une conduite intelligente et sÃ©curisÃ©e dans des environnements dynamiques.
category: robotics
tags:
  - Autonomous Driving
  - ROS2
  - Gazebo
  - Deep Reinforcement Learning
  - TD3
  - LIDAR
  - Computer Vision
  - Robotics
demo: /assets/videos/roborangers_demo.mp4
date: 2024-06-15
company: Academic Project
location: Ibn Tofail University, Kenitra
duration: February 2024 - June 2024
github: https://github.com/MEHDI57-NRG/RoboRangers
---

## ğŸ¯ Project Overview

**RoboRangers** est un projet de **voiture autonome** utilisant **Deep Reinforcement Learning (DRL)** et **ROS2** pour la navigation intelligente dans des environnements simulÃ©s. Le systÃ¨me intÃ¨gre des capteurs LIDAR et camÃ©ras pour une perception complÃ¨te, et implÃ©mente l'algorithme **TD3** (Twin Delayed Deep Deterministic Policy Gradient) pour la prise de dÃ©cision autonome.

**Ã‰quipe:**
- **ALAMI AROUSSI Zineb**
- **GRICHE MOHAMMED Imrane**
- **HICHAM EL Mehdi**
- **MOUTIA Salma**

**Sous la direction de:** Pr. BOUKIR Khaoula

**Mission:** DÃ©velopper un vÃ©hicule autonome capable de naviguer, Ã©viter les obstacles et respecter les panneaux de signalisation dans un environnement dynamique.

---

## ğŸ” Problem Statement

### Challenges

**ProblÃ©matique:** Comment permettre Ã  un systÃ¨me d'apprendre Ã  prendre des dÃ©cisions en temps rÃ©el en fonction des changements dans son environnement tout en garantissant sÃ©curitÃ© et efficacitÃ©?

- ğŸš— **Accidents routiers:** Erreurs humaines = principale cause de dÃ©cÃ¨s
- ğŸš¦ **Embouteillages:** Pertes Ã©conomiques et pollution
- ğŸ‘¥ **AccessibilitÃ©:** MobilitÃ© limitÃ©e pour personnes Ã¢gÃ©es/handicapÃ©es
- ğŸŒ **Impact environnemental:** Ã‰missions de CO2 Ã©levÃ©es
- ğŸ¯ **Navigation complexe:** Environnements dynamiques et imprÃ©visibles

### Solution

Voiture autonome intÃ©grant:
- **ROS2:** Communication inter-modules distribuÃ©e
- **Gazebo:** Simulation 3D rÃ©aliste pour tests sÃ©curisÃ©s
- **DRL (TD3):** Apprentissage autonome par essai-erreur
- **Capteurs multi-modaux:** LIDAR + CamÃ©ras pour perception 360Â°

---

## ğŸ—ï¸ Technical Architecture

<div align="center">

![RoboRangers Architecture](/assets/img/projects/roborangers_arch.png)

**Architecture systÃ¨me complÃ¨te RoboRangers**

</div>

---

### ğŸ”§ System Components

<table>
<tr>
<td width="50%" valign="top">

#### **Perception Layer**

![Sensors Integration](/assets/img/projects/roborangers_sensors.png)

**Capteurs:**
- ğŸ“¹ **CamÃ©ras RGB:** DÃ©tection obstacles, panneaux
- ğŸ”µ **LIDAR Velodyne:** Mesure distances 360Â°
- ğŸ“Š **Point Cloud Processing:** DonnÃ©es 3D temps rÃ©el
- ğŸ¯ **Fusion sensorielle:** Perception robuste

</td>
<td width="50%" valign="top">

#### **Decision & Control**

![TD3 Algorithm](/assets/img/projects/roborangers_td3.png)

**Intelligence:**
- ğŸ§  **TD3 Agent:** Apprentissage par renforcement
- ğŸ® **Action Selection:** Steering, accÃ©lÃ©ration, freinage
- ğŸ“ˆ **Reward Function:** SÃ©curitÃ© + efficacitÃ©
- ğŸ”„ **Continuous Learning:** AmÃ©lioration itÃ©rative

</td>
</tr>
</table>

---

### ğŸ“ ROS2 Architecture

```mermaid
graph TD
    A[ğŸ¥ Camera Node] --> D[Fusion Node]
    B[ğŸ”µ LIDAR Node] --> D
    C[ğŸ“ Localization Node] --> D
    D --> E[ğŸ§  TD3 DRL Agent]
    E --> F[ğŸ® Control Node]
    F --> G[ğŸš— Vehicle Actuators]
    G --> H[Gazebo Simulation]
    H --> A
    H --> B
    
    style E fill:#fff3cd
    style D fill:#e1f5ff
    style G fill:#d4edda
```

---

## âš™ï¸ ROS2 & Gazebo Integration

### ROS2 (Robot Operating System 2)

**Description:**
- Framework open-source pour dÃ©veloppement robotique
- Communication distribuÃ©e entre nÅ“uds
- Support multi-langages (Python, C++)
- Temps-rÃ©el et fiabilitÃ©

**Architecture de Communication:**
- **Publisher-Subscriber:** Topics pour Ã©change de donnÃ©es
- **Master Node:** Coordination des connexions
- **Messages standardisÃ©s:** Formats prÃ©dÃ©finis (sensor_msgs, geometry_msgs)

### Gazebo Simulator

**FonctionnalitÃ©s:**
- ğŸŒ **Environnement 3D rÃ©aliste:** Routes, obstacles, panneaux
- âš™ï¸ **Moteur physique:** GravitÃ©, collisions, friction
- ğŸ¤– **Multi-robots:** Simulations Ã  grande Ã©chelle
- ğŸ”— **IntÃ©gration ROS2:** Communication seamless

**Avantages:**
- Tests sÃ©curisÃ©s sans risque matÃ©riel
- ItÃ©rations rapides sur algorithmes
- ScÃ©narios reproductibles

---

## ğŸš€ TD3 (Twin Delayed DDPG) Algorithm

### Description

**TD3** amÃ©liore DDPG (Deep Deterministic Policy Gradient) avec 3 innovations:
1. **Twin Critics:** Deux rÃ©seaux critiques pour rÃ©duire biais
2. **Delayed Policy Updates:** Maj acteur moins frÃ©quente
3. **Target Policy Smoothing:** Bruit sur actions target

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         TD3 Agent                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  Actor Network (Î¼Î¸)                 â”‚
â”‚  â”œâ”€ Input: State (LIDAR + Image)   â”‚
â”‚  â””â”€ Output: Action (steering, vel) â”‚
â”‚                                     â”‚
â”‚  Twin Critic Networks (QÏ†1, QÏ†2)   â”‚
â”‚  â”œâ”€ Input: State + Action           â”‚
â”‚  â””â”€ Output: Q-value                 â”‚
â”‚                                     â”‚
â”‚  Replay Buffer                      â”‚
â”‚  â””â”€ Store: (s, a, r, s')            â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### State Space

| Composant | Description | Dimension |
|-----------|-------------|-----------|
| **LIDAR** | Distances obstacles 360Â° | 720 points |
| **Velocity** | Vitesse linÃ©aire/angulaire | 2 |
| **Goal** | Distance/angle vers objectif | 2 |
| **Total** | Ã‰tat complet | 724 |

### Action Space

| Action | Range | Description |
|--------|-------|-------------|
| **Steering** | [-1, 1] | Angle de rotation |
| **Velocity** | [0, 1] | Vitesse linÃ©aire |

### Reward Function

```python
reward = distance_to_goal * w1 
         - collision_penalty * w2
         - deviation_from_path * w3
         + goal_reached_bonus * w4
```

**Composantes:**
- âœ… **Progression:** RÃ©compense pour avancement vers objectif
- âŒ **Collisions:** PÃ©nalitÃ© Ã©levÃ©e (-100)
- ğŸ“ **Trajectoire:** PÃ©nalitÃ© pour dÃ©viation
- ğŸ¯ **Objectif atteint:** Bonus important (+100)

---

## ğŸ› ï¸ Implementation Details

### Project Structure

```
RoboRangers/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ td3/
â”‚       â”œâ”€â”€ models/              # URDF robot descriptions
â”‚       â”‚   â””â”€â”€ velodyne_description/
â”‚       â”œâ”€â”€ launch/              # ROS2 launch files
â”‚       â”‚   â””â”€â”€ launch_sim.launch.py
â”‚       â”œâ”€â”€ scripts/             # Python implementations
â”‚       â”‚   â”œâ”€â”€ train_velodyne_node.py
â”‚       â”‚   â”œâ”€â”€ test_velodyne_node.py
â”‚       â”‚   â”œâ”€â”€ replay_buffer.py
â”‚       â”‚   â””â”€â”€ td3_algorithm.py
â”‚       â”œâ”€â”€ pytorch_models/      # Trained models
â”‚       â”‚   â”œâ”€â”€ td3_velodyne_actor.pth
â”‚       â”‚   â””â”€â”€ td3_velodyne_critic.pth
â”‚       â””â”€â”€ worlds/              # Gazebo simulation worlds
â””â”€â”€ package.xml
```

### Training Configuration

**HyperparamÃ¨tres TD3:**
```python
config = {
    'actor_lr': 3e-4,
    'critic_lr': 3e-4,
    'gamma': 0.99,           # Discount factor
    'tau': 0.005,            # Target network update rate
    'policy_noise': 0.2,
    'noise_clip': 0.5,
    'policy_delay': 2,       # Actor update frequency
    'buffer_size': 1e6,
    'batch_size': 256
}
```

**Training Process:**
- Episodes: 1000+
- Max steps per episode: 500
- Training time: ~48h on RTX 4060

---

## ğŸ“Š Functionalities Achieved

### âœ… Core Features

| FonctionnalitÃ© | Status | Description |
|----------------|--------|-------------|
| **Navigation Autonome** | âœ… | Suivi de trajectoire prÃ©dÃ©finie |
| **DÃ©tection Obstacles** | âœ… | LIDAR + CamÃ©ras en temps rÃ©el |
| **Ã‰vitement Collisions** | âœ… | RÃ©action dynamique aux obstacles |
| **Reconnaissance Panneaux** | ğŸŸ¡ | DÃ©tection basique implÃ©mentÃ©e |
| **DRL Integration** | ğŸŸ¡ | TD3 partiellement intÃ©grÃ© |

### ğŸ¥ Visual Results

<div align="center">

![RoboRangers in Action](/assets/img/projects/roborangers_demo.png)

**Voiture autonome naviguant avec dÃ©tection d'obstacles (cÃ´nes + piÃ©tons)**

</div>

**LIDAR Visualization:**
- Lignes bleues: Rayons LIDAR
- Centre rouge: Position capteur
- Obstacles dÃ©tectÃ©s en temps rÃ©el

---

## ğŸ› ï¸ Challenges & Solutions

### Challenge 1: IntÃ©gration DRL

**ProblÃ¨me:** DifficultÃ©s environnementales ROS2-Gazebo-TD3  
**Status:** Partiellement rÃ©solu  
**Solution appliquÃ©e:**
- SÃ©paration des modules (perception / dÃ©cision / contrÃ´le)
- Tests unitaires indÃ©pendants
- Fallback sur contrÃ´le rÃ©actif simple

### Challenge 2: LIDAR Processing

**ProblÃ¨me:** Volume de donnÃ©es Ã©levÃ© (720 points @ 10Hz)  
**Solution:**
- Downsampling intelligent (720â†’180 points)
- Filtrage par distance (ROI: 0.5m - 10m)
- Processing GPU pour point cloud

### Challenge 3: Sim-to-Real Gap

**ProblÃ¨me:** Simulation â‰  RÃ©alitÃ© (physique, capteurs)  
**Solution future:**
- Domain randomization (friction, lighting)
- Sensor noise injection
- Sim2Real transfer learning

---

## ğŸ’¼ Impact & Value

### For Transportation

âœ… **RÃ©duction accidents:** -90% erreurs humaines  
âœ… **FluiditÃ© trafic:** Optimisation trajectoires  
âœ… **AccessibilitÃ©:** MobilitÃ© pour tous  
âœ… **Environnement:** -30% Ã©missions CO2  

### For Research

âœ… **Plateforme open-source** pour DRL robotique  
âœ… **Benchmark** ROS2 + Gazebo + TD3  
âœ… **ReproductibilitÃ©** via simulation  
âœ… **ExtensibilitÃ©** Ã  autres robots mobiles  

---

## ğŸ”® Future Improvements

**Short-Term:**
- Finaliser intÃ©gration TD3 complÃ¨te
- AmÃ©liorer reconnaissance panneaux (CNN)
- Multi-agent scenarios (plusieurs vÃ©hicules)

**Long-Term:**
- Deployment sur robot physique (TurtleBot3)
- Real-world testing avec capteurs rÃ©els
- V2V Communication (Vehicle-to-Vehicle)
- End-to-end learning (pixels â†’ actions)

---

## ğŸ› ï¸ Technical Stack

**Robotics:** ROS2 Humble, Gazebo 11  
**Deep Learning:** PyTorch, Stable-Baselines3  
**Sensors:** Velodyne LIDAR, RGB Cameras  
**Languages:** Python 3.10, C++  
**Tools:** Rviz, rqt, TensorBoard  
**Hardware:** NVIDIA RTX 4060, AMD Ryzen 7

---

## ğŸ“ Skills Developed

- **ROS2 Mastery:** Nodes, Topics, Services, Launch files
- **Reinforcement Learning:** TD3, DDPG, Actor-Critic
- **Sensor Fusion:** LIDAR + Camera integration
- **Robotics Simulation:** Gazebo worlds, URDF modeling
- **Autonomous Systems:** Path planning, obstacle avoidance

---

## ğŸ“š Key References

1. **TD3 Algorithm** (Fujimoto et al., 2018) - ICML
2. **ROS2 Documentation** - Open Robotics
3. **Gazebo Simulator** - OSRF
4. **Deep Reinforcement Learning** (Sutton & Barto, 2018)

---

## ğŸ“§ Contact

**Team Lead:** El Mehdi Hicham  
**Email:** mehdihicham736@gmail.com  
**GitHub:** [github.com/MEHDI57-NRG/RoboRangers](https://github.com/MEHDI57-NRG/RoboRangers)  
**LinkedIn:** [linkedin.com/in/elmehdihicham](https://linkedin.com/in/elmehdihicham)

**Team Members:**
- ALAMI AROUSSI Zineb
- GRICHE MOHAMMED Imrane
- MOUTIA Salma

**Supervisor:** Pr. BOUKIR Khaoula  
**Institution:** FacultÃ© des Sciences, Ibn Tofail University

---

## ğŸ† Achievements

âœ… **Navigation autonome** fonctionnelle dans Gazebo  
âœ… **DÃ©tection obstacles** temps rÃ©el (LIDAR + CamÃ©ras)  
âœ… **Architecture ROS2** modulaire et extensible  
âœ… **TD3 Agent** partiellement intÃ©grÃ©  
âœ… **Open-source** sur GitHub pour la communautÃ©  

---

*SystÃ¨me de conduite autonome combinant robotique moderne (ROS2), simulation rÃ©aliste (Gazebo) et intelligence artificielle (Deep RL) pour une mobilitÃ© sÃ»re et efficace.*