<!DOCTYPE html>

<!--
  portfolYOU Jekyll theme by yousinix
  Free for personal and commercial use under the MIT license
  https://github.com/yousinix/portfolYOU
-->

<html lang="en" class="h-100">

<head>

  
  
  

  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:type" content="website">
  <meta property="og:title" content="Azul OCR - Reconnaissance d&#39;Écriture Manuscrite Tifinagh">
  <meta property="og:description" content="Système OCR innovant utilisant CNN, Tesseract et PaddleOCR pour la reconnaissance de l'écriture manuscrite Tifinagh, préservant le patrimoine culturel Amazigh.">
  <meta property="og:image" content="/assets/img/projects/azul.jpeg">

  <title>Azul OCR - Reconnaissance d&#39;Écriture Manuscrite Tifinagh</title>
  <meta name="description" content="Système OCR innovant utilisant CNN, Tesseract et PaddleOCR pour la reconnaissance de l'écriture manuscrite Tifinagh, préservant le patrimoine culturel Amazigh.">

  <link rel="shortcut icon" type="image/x-icon" href="/Portfolio/assets/favicon.ico">

  <!-- Theme style -->
  <script src="/Portfolio/assets/js/theme.js"></script>

  <!-- Font Awesome CDN -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css">

  <!-- Bootstrap CSS CDN -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css">

  <!-- Animate CSS CDN -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/Portfolio/assets/css/style.css">

</head>


<body class="h-100 d-flex flex-column">

  <main class="flex-shrink-0 container mt-5">
    <nav class="navbar navbar-expand-lg navbar-themed">

  <a class="navbar-brand" href="/Portfolio/"><h5><b>Hicham El Mehdi</b></h5></a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <i class="fas fa-1x fa-bars text-themed"></i>
  </button>

  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav ml-auto"><a class="nav-item nav-link active" href="/Portfolio/projects/">My Projects</a>

      <a class="nav-item nav-link " href="/Portfolio/demos/">Demos</a>

      <a class="nav-item nav-link " href="/Portfolio/demos/futsal-analysis-demos.html">Futsal Analysis - Demos</a>

      <a class="nav-item nav-link " href="/Portfolio/about/">About</a>

      

      <span id="theme-toggler" class="nav-item nav-link" role="button" onclick="toggleTheme()"></span>
    </div>
  </div>

</nav>
    <style>
.project-detail {
  max-width: 900px;
  margin: 0 auto;
  padding: 3rem 2rem;
}

.project-header {
  text-align: center;
  margin-bottom: 3rem;
}

.project-header h1 {
  font-size: 2.5rem;
  font-weight: 700;
  background: linear-gradient(135deg, #58a6ff, #238636);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  margin-bottom: 1rem;
}

.project-meta {
  display: flex;
  justify-content: center;
  gap: 2rem;
  color: #9ba3b4;
  margin-bottom: 2rem;
}

.project-hero-image {
  width: 100%;
  max-height: 500px;
  object-fit: cover;
  border-radius: 16px;
  margin-bottom: 2rem;
}

.project-tags-detail {
  display: flex;
  flex-wrap: wrap;
  gap: 0.5rem;
  justify-content: center;
  margin-bottom: 2rem;
}

.project-tag-detail {
  padding: 0.5rem 1rem;
  background: rgba(88, 166, 255, 0.15);
  border: 1px solid rgba(88, 166, 255, 0.3);
  border-radius: 12px;
  font-size: 0.9rem;
  color: #58a6ff;
}

.project-actions {
  display: flex;
  gap: 1rem;
  justify-content: center;
  margin-bottom: 3rem;
}

.project-action-btn {
  padding: 0.8rem 1.5rem;
  border-radius: 8px;
  text-decoration: none;
  font-weight: 600;
  transition: all 0.3s ease;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.btn-github {
  background: rgba(35, 134, 54, 0.1);
  border: 1px solid rgba(35, 134, 54, 0.3);
  color: #238636;
}

.btn-github:hover {
  background: rgba(35, 134, 54, 0.2);
  transform: translateY(-2px);
}

.btn-demo {
  background: rgba(88, 166, 255, 0.1);
  border: 1px solid rgba(88, 166, 255, 0.3);
  color: #58a6ff;
}

.btn-demo:hover {
  background: rgba(88, 166, 255, 0.2);
  transform: translateY(-2px);
}

.project-content {
  color: #e6edf3;
  line-height: 1.8;
}

.project-content h2 {
  color: #58a6ff;
  margin-top: 2rem;
  margin-bottom: 1rem;
}

.project-content h3 {
  color: #9ba3b4;
  margin-top: 1.5rem;
}

.project-content ul, .project-content ol {
  margin-left: 1.5rem;
  color: #9ba3b4;
}

.back-link {
  text-align: center;
  margin-top: 3rem;
}

.back-link a {
  color: #58a6ff;
  text-decoration: none;
  font-weight: 600;
}

.back-link a:hover {
  text-decoration: underline;
}
</style>

<article class="project-detail">
  <header class="project-header">
    <h1>Azul OCR - Reconnaissance d'Écriture Manuscrite Tifinagh</h1>
    
    <div class="project-meta">
      
      <span>📅 March 2024</span>
      
      <span>📂 Computer vision</span>
    </div>

    
    <img src="/Portfolio/assets/img/projects/azul.jpeg" alt="Azul OCR - Reconnaissance d'Écriture Manuscrite Tifinagh" class="project-hero-image">
    

    
    <div class="project-tags-detail">
      
      <span class="project-tag-detail">OCR</span>
      
      <span class="project-tag-detail">Tifinagh</span>
      
      <span class="project-tag-detail">CNN</span>
      
      <span class="project-tag-detail">PaddleOCR</span>
      
      <span class="project-tag-detail">Tesseract</span>
      
      <span class="project-tag-detail">Cultural Heritage</span>
      
      <span class="project-tag-detail">Deep Learning</span>
      
      <span class="project-tag-detail">Computer Vision</span>
      
    </div>
    

    <div class="project-actions">
      

      
      <a href="/assets/videos/azul_ocr_demo.mp4" target="_blank" rel="noopener" class="project-action-btn btn-demo">
        <svg width="20" height="20" fill="currentColor" viewBox="0 0 16 16">
          <path d="M8 15A7 7 0 1 1 8 1a7 7 0 0 1 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
          <path d="M6.271 5.055a.5.5 0 0 1 .52.038l3.5 2.5a.5.5 0 0 1 0 .814l-3.5 2.5A.5.5 0 0 1 6 10.5v-5a.5.5 0 0 1 .271-.445z"/>
        </svg>
        Voir la démo
      </a>
      
    </div>
  </header>

  <div class="project-content">
    <h2 id="-project-overview">🎯 Project Overview</h2>

<p><strong>Azul OCR</strong> (ⴰⵣⵓⵍ - “Bonjour” en Amazigh) est un système OCR innovant spécialisé dans la <strong>reconnaissance de l’écriture manuscrite Tifinagh</strong>. Le projet vise à préserver et digitaliser le patrimoine culturel Amazigh en développant une solution d’intelligence artificielle capable de reconnaître précisément les caractères et phrases manuscrites en alphabet Tifinagh.</p>

<p><strong>Équipe:</strong></p>
<ul>
  <li><strong>Rima Daqch</strong> - Project Manager, Tesseract OCR Developer</li>
  <li><strong>Adil Eddarif</strong> - Tesseract OCR Developer, CNN Model Developer</li>
  <li><strong>Brahim El Aboudi</strong> - PaddleOCR Developer, CNN Model Developer</li>
  <li><strong>El Mehdi Hicham</strong> - PaddleOCR Developer, CNN Model Developer</li>
  <li><strong>Zineb Lahraoui</strong> - PaddleOCR Developer, CNN Model Developer</li>
</ul>

<p><strong>Encadré par:</strong> Prof. Khadija Lekdioui</p>

<p><strong>Mission:</strong> <em>“Préserver et digitaliser le patrimoine culturel Amazigh”</em></p>

<hr />

<h2 id="-problem-statement">🔍 Problem Statement</h2>

<h3 id="challenges">Challenges</h3>

<p><strong>“L’écriture Tifinagh est un élément essentiel du patrimoine culturel Amazigh, mais elle reste sous-représentée dans les outils technologiques modernes.”</strong></p>

<ul>
  <li>📚 <strong>Manque d’outils OCR:</strong> Aucune solution OCR dédiée aux manuscrits Tifinagh</li>
  <li>🎨 <strong>Complexité des caractères:</strong> Variabilité importante de l’écriture manuscrite</li>
  <li>⚠️ <strong>Risque culturel:</strong> Perte potentielle de contenus précieux pour les générations futures</li>
  <li>🔬 <strong>Précision limitée:</strong> Solutions existantes inadaptées aux spécificités du Tifinagh</li>
</ul>

<h3 id="solution">Solution</h3>

<p>Développement d’<strong>Azul OCR</strong>, système hybride combinant:</p>
<ul>
  <li><strong>Tesseract OCR</strong> fine-tuné pour le Tifinagh</li>
  <li><strong>PaddleOCR</strong> adapté aux caractères Amazighs</li>
  <li><strong>CNN personnalisé</strong> pour reconnaissance de caractères</li>
  <li><strong>Interface intuitive</strong> pour capture et reconnaissance</li>
</ul>

<hr />

<h2 id="️-technical-architecture">🏗️ Technical Architecture</h2>

<div align="center">

![Azul OCR Architecture](/assets/img/projects/azul_architecture.jpeg)

**Figure 1: Pipeline complet Azul OCR**

</div>

<hr />

<h3 id="-key-components">🔧 Key Components</h3>

<table>
<tr>
<td width="50%" valign="top">

#### **Module 1: Image Preprocessing**

![Preprocessing Pipeline](/assets/img/projects/azul_preprocessing.png)

**Techniques appliquées:**
- 🖼️ **Otsu Thresholding:** Binarisation automatique
- 📐 **Resizing:** 64×64 → 128×128 pixels
- 🎨 **Filtrage:** Réduction du bruit
- 🔄 **Augmentation:** Rotation, translation, zoom

</td>
<td width="50%" valign="top">

#### **Module 2: Recognition Engines**

![Recognition Models](/assets/img/projects/azul_models.png)

**Trois approches:**
- 📝 **Tesseract OCR:** Fine-tuné AMHCD dataset
- 🎯 **PaddleOCR:** Architecture légère adaptée
- 🧠 **CNN Custom:** Modèle entraîné from scratch
- 🔀 **Modèle hybride:** Fusion des prédictions

</td>
</tr>
</table>

<hr />

<h3 id="-system-workflow">📊 System Workflow</h3>

<pre><code class="language-mermaid">graph TD
    A[📸 Input Image] --&gt; B[Preprocessing]
    B --&gt; C{Detection Type}
    C --&gt;|Caractères| D[CNN Model]
    C --&gt;|Phrases| E[Tesseract/Paddle]
    D --&gt; F[Character Recognition]
    E --&gt; G[Phrase Recognition]
    F --&gt; H[📄 Output Text]
    G --&gt; H
    
    style A fill:#e1f5ff
    style H fill:#d4edda
    style C fill:#fff3cd
</code></pre>

<hr />

<h2 id="-dataset--preprocessing">📦 Dataset &amp; Preprocessing</h2>

<h3 id="amhcd-dataset">AMHCD Dataset</h3>

<p><strong>Source:</strong> IRCAM (Institut Royal de la Culture Amazighe)<br />
<strong>Collaborations:</strong> ENCG et Laboratoire IRF-SIC, Université Ibn Zohr, Agadir</p>

<p><strong>Caractéristiques:</strong></p>
<ul>
  <li>📊 <strong>33 classes</strong> de caractères Tifinagh</li>
  <li>🖼️ <strong>Format original:</strong> 64×64×3 (RGB)</li>
  <li>📈 <strong>Augmentation:</strong> ×5 par technique</li>
  <li>🎯 <strong>Résolution finale:</strong> 128×128 pixels</li>
</ul>

<h3 id="preprocessing-pipeline">Preprocessing Pipeline</h3>

<p><strong>Étape 1: Binarisation (Otsu)</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Seuillage automatique
</span><span class="n">threshold_value</span> <span class="o">=</span> <span class="n">otsu_threshold</span><span class="p">(</span><span class="n">grayscale_image</span><span class="p">)</span>
<span class="n">binary_image</span> <span class="o">=</span> <span class="n">apply_threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">threshold_value</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Étape 2: Redimensionnement</strong></p>
<ul>
  <li>Upscaling: 64×64 → 128×128 pour préserver détails</li>
  <li>Normalisation: Pixels [0, 255] → [0, 1]</li>
</ul>

<p><strong>Étape 3: Augmentation</strong>
| Technique | Paramètres |
|———–|————|
| Rotation | ±15° |
| Translation | ±10% |
| Zoom | 0.9-1.1× |
| Brightness | ±20% |</p>

<hr />

<h2 id="-model-architecture">🚀 Model Architecture</h2>

<h3 id="custom-cnn-model">Custom CNN Model</h3>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input (128×128×1)
    ↓
Conv2D (32 filters) + ReLU + MaxPool
    ↓
Conv2D (64 filters) + ReLU + MaxPool
    ↓
Conv2D (128 filters) + ReLU + MaxPool
    ↓
Flatten + Dense(256) + Dropout(0.5)
    ↓
Dense(33) + Softmax
</code></pre></div></div>

<p><strong>Hyperparamètres:</strong></p>
<ul>
  <li>Optimizer: Adam (lr=0.001)</li>
  <li>Loss: Categorical Crossentropy</li>
  <li>Batch Size: 32</li>
  <li>Epochs: 50</li>
</ul>

<h3 id="tesseract-fine-tuning">Tesseract Fine-Tuning</h3>

<ul>
  <li><strong>Baseline:</strong> Tesseract 4.0 pré-entraîné</li>
  <li><strong>Fine-tuning:</strong> AMHCD dataset (2000+ samples)</li>
  <li><strong>Language:</strong> <code class="language-plaintext highlighter-rouge">tif</code> (Tifinagh custom traineddata)</li>
</ul>

<h3 id="paddleocr-adaptation">PaddleOCR Adaptation</h3>

<ul>
  <li><strong>Architecture:</strong> Lightweight PP-OCRv3</li>
  <li><strong>Detection:</strong> DB++ (Differentiable Binarization)</li>
  <li><strong>Recognition:</strong> CRNN fine-tuné sur Tifinagh</li>
</ul>

<hr />

<h2 id="-results--performance">📊 Results &amp; Performance</h2>

<h3 id="character-recognition-cnn">Character Recognition (CNN)</h3>

<table>
  <thead>
    <tr>
      <th>Métrique</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Accuracy</strong></td>
      <td>94.2%</td>
    </tr>
    <tr>
      <td><strong>Precision</strong></td>
      <td>93.8%</td>
    </tr>
    <tr>
      <td><strong>Recall</strong></td>
      <td>94.5%</td>
    </tr>
    <tr>
      <td><strong>F1-Score</strong></td>
      <td>94.1%</td>
    </tr>
  </tbody>
</table>

<h3 id="phrase-recognition">Phrase Recognition</h3>

<table>
  <thead>
    <tr>
      <th>Modèle</th>
      <th>Accuracy</th>
      <th>CER*</th>
      <th>WER**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Tesseract</strong></td>
      <td>87.3%</td>
      <td>12.5%</td>
      <td>18.2%</td>
    </tr>
    <tr>
      <td><strong>PaddleOCR</strong></td>
      <td>89.6%</td>
      <td>10.8%</td>
      <td>15.4%</td>
    </tr>
    <tr>
      <td><strong>Hybrid</strong>*</td>
      <td>91.2%</td>
      <td>9.1%</td>
      <td>13.7%</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>*CER: Character Error Rate</td>
      <td>**WER: Word Error Rate</td>
      <td>***Fusion weighted voting</td>
    </tr>
  </tbody>
</table>

<h3 id="performance-comparison">Performance Comparison</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌──────────────────────────────────────────┐
│     Accuracy par Modèle                  │
├──────────────────────────────────────────┤
│ CNN (chars):     ████████████░  94.2%    │
│ PaddleOCR:       ████████████░  89.6%    │
│ Tesseract:       ███████████░░  87.3%    │
│ Hybrid Model:    █████████████  91.2% ⭐ │
└──────────────────────────────────────────┘
</code></pre></div></div>

<hr />

<h2 id="-user-interface">💻 User Interface</h2>

<h3 id="features">Features</h3>

<p>✅ <strong>Upload Image:</strong> Support PNG, JPG, JPEG<br />
✅ <strong>Take Picture:</strong> Capture directe via webcam<br />
✅ <strong>Real-time Recognition:</strong> Résultats instantanés<br />
✅ <strong>Copy Output:</strong> Copie du texte reconnu<br />
✅ <strong>Multi-format Export:</strong> TXT, JSON, CSV</p>

<h3 id="interface-screenshots">Interface Screenshots</h3>

<div align="center">

![Azul Interface]("/assets/img/projects/azul_interface.jepg")

**Interface utilisateur intuitive d'Azul OCR**

</div>

<hr />

<h2 id="️-challenges--solutions">🛠️ Challenges &amp; Solutions</h2>

<h3 id="challenge-1-variabilité-de-lécriture-manuscrite">Challenge 1: Variabilité de l’Écriture Manuscrite</h3>

<p><strong>Problème:</strong> Grande diversité de styles d’écriture<br />
<strong>Solution:</strong></p>
<ul>
  <li>Augmentation intensive (×5)</li>
  <li>Modèle hybride (fusion de 3 approches)</li>
  <li>Fine-tuning sur données réelles</li>
</ul>

<h3 id="challenge-2-dataset-limité">Challenge 2: Dataset Limité</h3>

<p><strong>Problème:</strong> Peu de données annotées disponibles<br />
<strong>Solution:</strong></p>
<ul>
  <li>Collaboration avec IRCAM</li>
  <li>Data augmentation aggressive</li>
  <li>Transfer learning depuis modèles pré-entraînés</li>
</ul>

<h3 id="challenge-3-reconnaissance-de-phrases">Challenge 3: Reconnaissance de Phrases</h3>

<p><strong>Problème:</strong> Segmentation difficile entre mots<br />
<strong>Solution:</strong></p>
<ul>
  <li>Utilisation de PaddleOCR pour détection</li>
  <li>Post-processing avec règles linguistiques</li>
  <li>Correction contextuelle</li>
</ul>

<hr />

<h2 id="-impact--value">💼 Impact &amp; Value</h2>

<h3 id="for-cultural-heritage">For Cultural Heritage</h3>

<p>✅ <strong>Préservation numérique</strong> de manuscrits anciens<br />
✅ <strong>Accessibilité</strong> des textes Amazighs à tous<br />
✅ <strong>Éducation</strong> facilitée pour les nouvelles générations<br />
✅ <strong>Recherche</strong> académique sur la culture Amazigh</p>

<h3 id="for-institutions">For Institutions</h3>

<p>✅ <strong>Digitalisation rapide</strong> des archives<br />
✅ <strong>Indexation automatique</strong> de documents<br />
✅ <strong>Recherche textuelle</strong> dans corpus numériques<br />
✅ <strong>Coûts réduits</strong> vs annotation manuelle</p>

<hr />

<h2 id="-future-improvements">🔮 Future Improvements</h2>

<p><strong>Short-Term:</strong></p>
<ul>
  <li>Améliorer précision sur phrases complexes (&gt;95%)</li>
  <li>Support de variantes régionales du Tifinagh</li>
  <li>API REST pour intégration externe</li>
</ul>

<p><strong>Long-Term:</strong></p>
<ul>
  <li>Application mobile (iOS/Android)</li>
  <li>Reconnaissance de textes historiques dégradés</li>
  <li>Extension à d’autres alphabets africains</li>
  <li>OCR multilingue (Tifinagh + Latin + Arabe)</li>
</ul>

<hr />

<h2 id="️-technical-stack">🛠️ Technical Stack</h2>

<p><strong>Deep Learning:</strong> TensorFlow, Keras, PyTorch<br />
<strong>OCR Engines:</strong> Tesseract 4.0, PaddleOCR<br />
<strong>Computer Vision:</strong> OpenCV, scikit-image<br />
<strong>Frontend:</strong> React.js, HTML5, CSS3<br />
<strong>Backend:</strong> Flask, FastAPI<br />
<strong>Deployment:</strong> Docker, Heroku</p>

<hr />

<h2 id="-skills-developed">🎓 Skills Developed</h2>

<ul>
  <li><strong>OCR Development:</strong> Fine-tuning Tesseract/PaddleOCR</li>
  <li><strong>CNN Architecture:</strong> Custom model design</li>
  <li><strong>Image Processing:</strong> Otsu, filtering, augmentation</li>
  <li><strong>Team Collaboration:</strong> 5-person agile team</li>
  <li><strong>Cultural Awareness:</strong> Amazigh heritage preservation</li>
</ul>

<hr />

<h2 id="-key-references">📚 Key References</h2>

<ol>
  <li><strong>Tesseract OCR</strong> - Google Open Source</li>
  <li><strong>PaddleOCR</strong> - PaddlePaddle Team</li>
  <li><strong>AMHCD Dataset</strong> - IRCAM &amp; Université Ibn Zohr</li>
  <li><strong>Otsu Thresholding</strong> - IEEE Trans. SMC (1979)</li>
</ol>

<hr />

<h2 id="-contact">📧 Contact</h2>

<p><strong>Team Lead:</strong> Rima Daqch<br />
<strong>Technical Lead:</strong> El Mehdi Hicham<br />
<strong>Email:</strong> mehdihicham736@gmail.com<br />
<strong>LinkedIn:</strong> <a href="https://linkedin.com/in/elmehdihicham">linkedin.com/in/elmehdihicham</a><br />
<strong>GitHub:</strong> <a href="https://github.com/MehdiHCH">github.com/MehdiHCH</a></p>

<p><strong>Supervisor:</strong> Prof. Khadija Lekdioui<br />
<strong>Institution:</strong> Faculté des Sciences, Ibn Tofail University</p>

<hr />

<h2 id="-achievements">🏆 Achievements</h2>

<p>✅ <strong>94.2% Accuracy</strong> sur reconnaissance de caractères<br />
✅ <strong>91.2% Accuracy</strong> sur reconnaissance de phrases (hybride)<br />
✅ <strong>Premier OCR Tifinagh</strong> open-source au Maroc<br />
✅ <strong>Collaboration institutionnelle</strong> avec IRCAM<br />
✅ <strong>Interface intuitive</strong> testée par 50+ utilisateurs</p>

<hr />

<p><em>“Chaque manuscrit oublié est une voix de l’humanité réduite au silence.”</em><br />
<em>ⵛⴰⵇⴰ ⵎⴰⵏⵓⵙⵖⵔⵉⵜ ⵓⴱⵍⵉⵎ ⴻⵙⵜ ⵓⵏⴻ ⵓⵡⵏⴰⵙ ⴷⴻ ⵍⵓⵎⵍⵉⵏⵏⵉⵏ ⵔⴻⵙⵓⵉⵜⴰ ⵓⵢ ⵙⵉⵍⵓⵏⵉⵛ</em></p>

<p><em>Azul OCR - L’IA au service du patrimoine culturel Amazigh</em></p>

  </div>

  <div class="back-link">
    <a href="/Portfolio/projects/">← Retour aux projets</a>
  </div>
</article>
  </main>
  <footer class="mt-auto py-3 text-center">

  <small class="text-muted mb-2">
    <i class="fas fa-code"></i> with <i class="fas fa-heart"></i>
    by <strong>EL MEHDI Hicham</strong>
  </small>

  <div class="container-fluid justify-content-center"><a class="social mx-1"  href="mailto:mehdihicham736@gmail.com"
       style="color: #6c757d"
       onMouseOver="this.style.color='#db4437'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fas fa-envelope fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.github.com/MehdiHCH"
       style="color: #6c757d"
       onMouseOver="this.style.color='#333333'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-github fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.linkedin.com/in/elmehdihicham"
       style="color: #6c757d"
       onMouseOver="this.style.color='#007bb5'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-linkedin-in fa-1x"></i>
    </a>

</div><small id="attribution">
    theme <a href="https://github.com/yousinix/portfolYOU">portfolYOU</a>
  </small>

</footer>

  
  <!-- GitHub Buttons -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper.js CDN -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>

<!-- Bootstrap JS CDN -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<!-- wow.js CDN & Activation -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.js"></script>
<script> new WOW().init(); </script>

<!-- Initialize all tooltips -->
<script>
$(function () {
    $('[data-toggle="tooltip"]').tooltip()
})
</script>
</body>

</html>